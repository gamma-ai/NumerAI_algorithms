{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _*Quantum SVM kernel algorithm:  multiclass classifier extension*_\n",
    "\n",
    "A multiclass extension works in conjunction with an underlying binary (two class) classifier to provide multiclass classification.\n",
    "\n",
    "Currently three different multiclass extensions are supported:\n",
    "\n",
    "* OneAgainstRest\n",
    "* AllPairs\n",
    "* ErrorCorrectingCode\n",
    "\n",
    "These use different techniques to group the data with binary classification to achieve the final multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T07:51:45.764367Z",
     "start_time": "2019-05-03T07:51:14.974188Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from qiskit import Aer\n",
    "from qiskit_aqua.input import SVMInput\n",
    "from qiskit_aqua import run_algorithm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose the `Wine` dataset which has 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T08:18:49.048350Z",
     "start_time": "2019-05-03T08:18:37.560250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "original train data shape: 502732,\t60 \n",
      "\n",
      " \t:\n",
      "original prediction data shape: 333924,\t60 \n",
      "\n",
      " \t:\n",
      "total training / valdation shape                       id   era data_type  feature1  feature2  feature3  \\\n",
      "0       n0003126ff2349f6  era1     train   0.54836   0.31077   0.37524   \n",
      "1       n003d773d29b57ec  era1     train   0.34712   0.40275   0.42747   \n",
      "2       n0074df2dc6810b6  era1     train   0.50871   0.48639   0.47544   \n",
      "3       n0090630f530903e  era1     train   0.61363   0.40268   0.53779   \n",
      "4       n00af19089546fe9  era1     train   0.30704   0.47273   0.54495   \n",
      "5       n011d2da12b1e735  era1     train   0.52336   0.59136   0.60506   \n",
      "6       n014149cadeee55d  era1     train   0.30875   0.62510   0.35229   \n",
      "7       n0148a4dcf539aba  era1     train   0.40632   0.30590   0.43227   \n",
      "8       n015855690d31908  era1     train   0.48193   0.27060   0.50228   \n",
      "9       n0169447f4d6a10e  era1     train   0.51191   0.53663   0.42109   \n",
      "10      n01703ba4eff8fe7  era1     train   0.51829   0.52928   0.41085   \n",
      "11      n01b43e631083764  era1     train   0.61895   0.44075   0.61466   \n",
      "12      n01d1368b061433f  era1     train   0.45529   0.28276   0.61272   \n",
      "13      n01d5bfde31734cd  era1     train   0.48717   0.28982   0.38631   \n",
      "14      n0236fa89e606631  era1     train   0.42585   0.56616   0.62732   \n",
      "15      n023dfa017b93739  era1     train   0.51657   0.52352   0.41695   \n",
      "16      n0294f04019898e8  era1     train   0.45073   0.56795   0.25294   \n",
      "17      n029adf0fa156932  era1     train   0.53833   0.43619   0.58892   \n",
      "18      n02ad6457589c4af  era1     train   0.33576   0.54933   0.39919   \n",
      "19      n02bd240c01b24bd  era1     train   0.47469   0.38517   0.53743   \n",
      "20      n02c48c74a9c9719  era1     train   0.83431   0.36147   0.69324   \n",
      "21      n02cc6384ea5a025  era1     train   0.49314   0.31000   0.36538   \n",
      "22      n02e0356c793b120  era1     train   0.65183   0.40688   0.52271   \n",
      "23      n02e96eeb774238f  era1     train   0.67869   0.46261   0.38758   \n",
      "24      n030964ace7cfa93  era1     train   0.59925   0.43286   0.46698   \n",
      "25      n0311b410c7f8b9d  era1     train   0.37634   0.43578   0.43619   \n",
      "26      n03158868e546c31  era1     train   0.50558   0.47651   0.53912   \n",
      "27      n032f0f9107b0115  era1     train   0.46657   0.28710   0.44637   \n",
      "28      n03484f670162e63  era1     train   0.33571   0.45678   0.25402   \n",
      "29      n03534209c17edf5  era1     train   0.35224   0.48464   0.47109   \n",
      "...                  ...   ...       ...       ...       ...       ...   \n",
      "333894  nfec21cd5c5b33ad  eraX      live   0.38965   0.45030   0.52700   \n",
      "333895  nfec98c25ae22d54  eraX      live   0.69356   0.47442   0.50694   \n",
      "333896  nfed0b30d2d442cc  eraX      live   0.38492   0.42707   0.44937   \n",
      "333897  nfed69bed5d087e9  eraX      live   0.48369   0.62619   0.38787   \n",
      "333898  nfed8728787c35f7  eraX      live   0.49617   0.44814   0.45066   \n",
      "333899  nfeda5d5d6cfa79e  eraX      live   0.62005   0.29275   0.30218   \n",
      "333900  nfeeb6e4cd56ca3a  eraX      live   0.51599   0.49497   0.68660   \n",
      "333901  nfef1f9ddc8df2af  eraX      live   0.34322   0.31093   0.49169   \n",
      "333902  nff08e8747d575c2  eraX      live   0.49919   0.54032   0.71305   \n",
      "333903  nff1e7fb2384e709  eraX      live   0.62816   0.54499   0.67274   \n",
      "333904  nff3a0d69e6a871e  eraX      live   0.76577   0.46736   0.48493   \n",
      "333905  nff430c26ed109de  eraX      live   0.47557   0.35675   0.57149   \n",
      "333906  nff62b58beb64c4f  eraX      live   0.42865   0.60958   0.56111   \n",
      "333907  nff7234fd21aa8ed  eraX      live   0.39509   0.46559   0.51895   \n",
      "333908  nff73210358cd504  eraX      live   0.65093   0.43259   0.42214   \n",
      "333909  nff770cbee3cd1bf  eraX      live   0.27143   0.73245   0.57361   \n",
      "333910  nff939fd6397eb8d  eraX      live   0.37668   0.35264   0.45309   \n",
      "333911  nff94fb2bec22d22  eraX      live   0.31030   0.40159   0.46879   \n",
      "333912  nff9af0d05671f92  eraX      live   0.46025   0.33584   0.45436   \n",
      "333913  nffba5bfdde304d5  eraX      live   0.40388   0.34720   0.62989   \n",
      "333914  nffbe892b3bf9fe7  eraX      live   0.65109   0.27549   0.19570   \n",
      "333915  nffc2a2b2ef54a97  eraX      live   0.45028   0.43775   0.64112   \n",
      "333916  nffd3c0fbc2de0e8  eraX      live   0.40023   0.39563   0.37794   \n",
      "333917  nffd754673e8f726  eraX      live   0.55810   0.50070   0.37339   \n",
      "333918  nffdb5c4428c68c3  eraX      live   0.47117   0.49835   0.43437   \n",
      "333919  nffdb97eb02f3e90  eraX      live   0.78880   0.47460   0.61443   \n",
      "333920  nffe15031d080c66  eraX      live   0.49492   0.50500   0.57896   \n",
      "333921  nffedbfc9ba8f6b2  eraX      live   0.31902   0.52280   0.52200   \n",
      "333922  nfff54490e982036  eraX      live   0.48698   0.59598   0.56342   \n",
      "333923  nfffcee8f1fddd45  eraX      live   0.56285   0.57647   0.52050   \n",
      "\n",
      "        feature4  feature5  feature6  feature7  ...  feature48  feature49  \\\n",
      "0        0.49490   0.53217   0.48388   0.50220  ...    0.55239    0.64054   \n",
      "1        0.44006   0.47866   0.44055   0.59182  ...    0.46029    0.62941   \n",
      "2        0.40306   0.53436   0.64028   0.51420  ...    0.40596    0.54731   \n",
      "3        0.37045   0.58711   0.59900   0.62428  ...    0.53878    0.47776   \n",
      "4        0.48692   0.47348   0.34695   0.41506  ...    0.46431    0.49482   \n",
      "5        0.30085   0.41742   0.47290   0.56301  ...    0.55917    0.31260   \n",
      "6        0.48021   0.71347   0.36977   0.57899  ...    0.40538    0.52690   \n",
      "7        0.61999   0.51016   0.52714   0.74017  ...    0.77664    0.51623   \n",
      "8        0.63037   0.50734   0.45545   0.41927  ...    0.52887    0.44384   \n",
      "9        0.38838   0.51222   0.53249   0.70187  ...    0.58353    0.42566   \n",
      "10       0.44842   0.49727   0.66198   0.53513  ...    0.54271    0.43434   \n",
      "11       0.51365   0.45339   0.51101   0.39488  ...    0.33293    0.30265   \n",
      "12       0.48615   0.54590   0.59111   0.55893  ...    0.55932    0.46798   \n",
      "13       0.58569   0.46994   0.51753   0.41116  ...    0.55347    0.42172   \n",
      "14       0.40727   0.36868   0.51526   0.29604  ...    0.53480    0.48525   \n",
      "15       0.39198   0.54481   0.55880   0.48240  ...    0.45665    0.50711   \n",
      "16       0.37918   0.65944   0.61828   0.62431  ...    0.44610    0.57642   \n",
      "17       0.53740   0.32951   0.44737   0.39056  ...    0.64044    0.22801   \n",
      "18       0.51449   0.44705   0.53717   0.53424  ...    0.53355    0.49124   \n",
      "19       0.46013   0.63523   0.48265   0.50777  ...    0.48970    0.41920   \n",
      "20       0.49827   0.22947   0.46324   0.49544  ...    0.75846    0.31290   \n",
      "21       0.49332   0.68842   0.59665   0.57461  ...    0.54245    0.40880   \n",
      "22       0.69467   0.62700   0.50894   0.44084  ...    0.64244    0.17882   \n",
      "23       0.33676   0.43296   0.56874   0.67007  ...    0.63132    0.46647   \n",
      "24       0.39413   0.58728   0.38304   0.60579  ...    0.50472    0.33878   \n",
      "25       0.45756   0.39833   0.58444   0.48982  ...    0.58255    0.52865   \n",
      "26       0.48904   0.43819   0.53960   0.55395  ...    0.49973    0.47976   \n",
      "27       0.50982   0.63898   0.45895   0.50982  ...    0.52851    0.43489   \n",
      "28       0.47962   0.50144   0.58369   0.62196  ...    0.79120    0.72922   \n",
      "29       0.41567   0.57632   0.34524   0.58772  ...    0.47177    0.55393   \n",
      "...          ...       ...       ...       ...  ...        ...        ...   \n",
      "333894   0.37210   0.46008   0.43412   0.63377  ...    0.57366    0.62540   \n",
      "333895   0.41392   0.47895   0.66038   0.49995  ...    0.62853    0.29633   \n",
      "333896   0.42662   0.54812   0.49072   0.66651  ...    0.48536    0.48631   \n",
      "333897   0.14462   0.56918   0.42828   0.64804  ...    0.54346    0.46759   \n",
      "333898   0.42089   0.68011   0.53420   0.57086  ...    0.43619    0.35083   \n",
      "333899   0.48158   0.45471   0.62305   0.59370  ...    0.43859    0.48730   \n",
      "333900   0.51868   0.35298   0.41149   0.45650  ...    0.50594    0.37331   \n",
      "333901   0.59407   0.61595   0.40386   0.65190  ...    0.49023    0.60424   \n",
      "333902   0.49465   0.71118   0.48220   0.53299  ...    0.41879    0.64955   \n",
      "333903   0.39532   0.30184   0.20910   0.33041  ...    0.59970    0.59045   \n",
      "333904   0.37545   0.50035   0.64585   0.55769  ...    0.59497    0.38776   \n",
      "333905   0.42187   0.47466   0.37525   0.58125  ...    0.52464    0.57618   \n",
      "333906   0.35536   0.48186   0.49876   0.36463  ...    0.58487    0.44765   \n",
      "333907   0.32089   0.69535   0.53294   0.43689  ...    0.40198    0.54004   \n",
      "333908   0.43413   0.64938   0.66657   0.62922  ...    0.64106    0.46986   \n",
      "333909   0.40323   0.49161   0.38526   0.35060  ...    0.46227    0.52369   \n",
      "333910   0.55636   0.50846   0.47913   0.55327  ...    0.41672    0.52240   \n",
      "333911   0.45420   0.58696   0.25287   0.48149  ...    0.44196    0.68500   \n",
      "333912   0.46719   0.55669   0.59600   0.53443  ...    0.54857    0.59703   \n",
      "333913   0.50223   0.51333   0.59573   0.19037  ...    0.38403    0.52610   \n",
      "333914   0.29505   0.64040   0.65133   0.82701  ...    0.68128    0.66397   \n",
      "333915   0.62979   0.49950   0.31329   0.29323  ...    0.47624    0.54389   \n",
      "333916   0.41597   0.58451   0.46737   0.42167  ...    0.36073    0.65194   \n",
      "333917   0.22398   0.53908   0.69242   0.73459  ...    0.69416    0.50256   \n",
      "333918   0.40502   0.52326   0.55660   0.46356  ...    0.54289    0.53682   \n",
      "333919   0.29016   0.54173   0.49867   0.54847  ...    0.48866    0.35555   \n",
      "333920   0.39936   0.27492   0.42211   0.20965  ...    0.56749    0.54948   \n",
      "333921   0.42636   0.55033   0.51607   0.55940  ...    0.47780    0.53887   \n",
      "333922   0.56995   0.54684   0.36167   0.45931  ...    0.67469    0.58980   \n",
      "333923   0.41839   0.56140   0.59366   0.51704  ...    0.62566    0.45478   \n",
      "\n",
      "        feature50  target_bernie  target_elizabeth  target_jordan  target_ken  \\\n",
      "0         0.52182            1.0               1.0            1.0         1.0   \n",
      "1         0.55010            1.0               1.0            1.0         1.0   \n",
      "2         0.39061            0.0               0.0            1.0         0.0   \n",
      "3         0.36835            0.0               0.0            0.0         0.0   \n",
      "4         0.60452            1.0               1.0            1.0         1.0   \n",
      "5         0.35691            0.0               0.0            0.0         0.0   \n",
      "6         0.39767            1.0               1.0            1.0         1.0   \n",
      "7         0.49104            0.0               0.0            0.0         0.0   \n",
      "8         0.57269            0.0               0.0            0.0         0.0   \n",
      "9         0.50082            1.0               1.0            1.0         1.0   \n",
      "10        0.52720            0.0               0.0            0.0         0.0   \n",
      "11        0.45951            0.0               0.0            0.0         0.0   \n",
      "12        0.53359            1.0               1.0            1.0         1.0   \n",
      "13        0.72972            0.0               0.0            0.0         0.0   \n",
      "14        0.59524            1.0               1.0            1.0         1.0   \n",
      "15        0.59955            0.0               0.0            0.0         0.0   \n",
      "16        0.62569            0.0               0.0            0.0         0.0   \n",
      "17        0.44203            1.0               1.0            1.0         1.0   \n",
      "18        0.39731            1.0               1.0            1.0         1.0   \n",
      "19        0.38751            0.0               0.0            0.0         0.0   \n",
      "20        0.61816            1.0               1.0            1.0         1.0   \n",
      "21        0.53372            0.0               1.0            0.0         0.0   \n",
      "22        0.40123            0.0               0.0            0.0         0.0   \n",
      "23        0.53402            0.0               0.0            0.0         0.0   \n",
      "24        0.56262            0.0               0.0            0.0         0.0   \n",
      "25        0.63495            0.0               0.0            0.0         0.0   \n",
      "26        0.44513            0.0               0.0            0.0         0.0   \n",
      "27        0.48806            0.0               0.0            0.0         1.0   \n",
      "28        0.49451            0.0               0.0            0.0         0.0   \n",
      "29        0.49058            1.0               1.0            1.0         1.0   \n",
      "...           ...            ...               ...            ...         ...   \n",
      "333894    0.60923            NaN               NaN            NaN         NaN   \n",
      "333895    0.44433            NaN               NaN            NaN         NaN   \n",
      "333896    0.48360            NaN               NaN            NaN         NaN   \n",
      "333897    0.35499            NaN               NaN            NaN         NaN   \n",
      "333898    0.58263            NaN               NaN            NaN         NaN   \n",
      "333899    0.59974            NaN               NaN            NaN         NaN   \n",
      "333900    0.53860            NaN               NaN            NaN         NaN   \n",
      "333901    0.54947            NaN               NaN            NaN         NaN   \n",
      "333902    0.39121            NaN               NaN            NaN         NaN   \n",
      "333903    0.55970            NaN               NaN            NaN         NaN   \n",
      "333904    0.58773            NaN               NaN            NaN         NaN   \n",
      "333905    0.60564            NaN               NaN            NaN         NaN   \n",
      "333906    0.34334            NaN               NaN            NaN         NaN   \n",
      "333907    0.43746            NaN               NaN            NaN         NaN   \n",
      "333908    0.42161            NaN               NaN            NaN         NaN   \n",
      "333909    0.61633            NaN               NaN            NaN         NaN   \n",
      "333910    0.62184            NaN               NaN            NaN         NaN   \n",
      "333911    0.49960            NaN               NaN            NaN         NaN   \n",
      "333912    0.58098            NaN               NaN            NaN         NaN   \n",
      "333913    0.47645            NaN               NaN            NaN         NaN   \n",
      "333914    0.49876            NaN               NaN            NaN         NaN   \n",
      "333915    0.30022            NaN               NaN            NaN         NaN   \n",
      "333916    0.60008            NaN               NaN            NaN         NaN   \n",
      "333917    0.49471            NaN               NaN            NaN         NaN   \n",
      "333918    0.32950            NaN               NaN            NaN         NaN   \n",
      "333919    0.50956            NaN               NaN            NaN         NaN   \n",
      "333920    0.40728            NaN               NaN            NaN         NaN   \n",
      "333921    0.42454            NaN               NaN            NaN         NaN   \n",
      "333922    0.41426            NaN               NaN            NaN         NaN   \n",
      "333923    0.37560            NaN               NaN            NaN         NaN   \n",
      "\n",
      "        target_charles  target_frank  target_hillary  \n",
      "0                  1.0           1.0             1.0  \n",
      "1                  1.0           1.0             1.0  \n",
      "2                  0.0           0.0             0.0  \n",
      "3                  0.0           0.0             0.0  \n",
      "4                  1.0           1.0             1.0  \n",
      "5                  0.0           0.0             0.0  \n",
      "6                  1.0           1.0             1.0  \n",
      "7                  0.0           0.0             0.0  \n",
      "8                  0.0           0.0             0.0  \n",
      "9                  1.0           1.0             1.0  \n",
      "10                 0.0           0.0             0.0  \n",
      "11                 0.0           0.0             0.0  \n",
      "12                 1.0           1.0             1.0  \n",
      "13                 0.0           0.0             0.0  \n",
      "14                 1.0           1.0             1.0  \n",
      "15                 1.0           1.0             0.0  \n",
      "16                 0.0           0.0             0.0  \n",
      "17                 1.0           1.0             1.0  \n",
      "18                 1.0           1.0             1.0  \n",
      "19                 0.0           0.0             1.0  \n",
      "20                 1.0           1.0             1.0  \n",
      "21                 0.0           1.0             1.0  \n",
      "22                 0.0           0.0             0.0  \n",
      "23                 0.0           0.0             0.0  \n",
      "24                 0.0           0.0             0.0  \n",
      "25                 0.0           0.0             0.0  \n",
      "26                 0.0           0.0             0.0  \n",
      "27                 0.0           0.0             1.0  \n",
      "28                 0.0           0.0             0.0  \n",
      "29                 1.0           1.0             1.0  \n",
      "...                ...           ...             ...  \n",
      "333894             NaN           NaN             NaN  \n",
      "333895             NaN           NaN             NaN  \n",
      "333896             NaN           NaN             NaN  \n",
      "333897             NaN           NaN             NaN  \n",
      "333898             NaN           NaN             NaN  \n",
      "333899             NaN           NaN             NaN  \n",
      "333900             NaN           NaN             NaN  \n",
      "333901             NaN           NaN             NaN  \n",
      "333902             NaN           NaN             NaN  \n",
      "333903             NaN           NaN             NaN  \n",
      "333904             NaN           NaN             NaN  \n",
      "333905             NaN           NaN             NaN  \n",
      "333906             NaN           NaN             NaN  \n",
      "333907             NaN           NaN             NaN  \n",
      "333908             NaN           NaN             NaN  \n",
      "333909             NaN           NaN             NaN  \n",
      "333910             NaN           NaN             NaN  \n",
      "333911             NaN           NaN             NaN  \n",
      "333912             NaN           NaN             NaN  \n",
      "333913             NaN           NaN             NaN  \n",
      "333914             NaN           NaN             NaN  \n",
      "333915             NaN           NaN             NaN  \n",
      "333916             NaN           NaN             NaN  \n",
      "333917             NaN           NaN             NaN  \n",
      "333918             NaN           NaN             NaN  \n",
      "333919             NaN           NaN             NaN  \n",
      "333920             NaN           NaN             NaN  \n",
      "333921             NaN           NaN             NaN  \n",
      "333922             NaN           NaN             NaN  \n",
      "333923             NaN           NaN             NaN  \n",
      "\n",
      "[836656 rows x 60 columns]\n",
      "['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9', 'feature10', 'feature11', 'feature12', 'feature13', 'feature14', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature21', 'feature22', 'feature23', 'feature24', 'feature25', 'feature26', 'feature27', 'feature28', 'feature29', 'feature30', 'feature31', 'feature32', 'feature33', 'feature34', 'feature35', 'feature36', 'feature37', 'feature38', 'feature39', 'feature40', 'feature41', 'feature42', 'feature43', 'feature44', 'feature45', 'feature46', 'feature47', 'feature48', 'feature49', 'feature50']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.51955835  2.5696983 ]\n",
      " [-5.62540317 -0.68585251]\n",
      " [ 3.88984766 -2.86869062]\n",
      " [-3.46167742  3.5214927 ]\n",
      " [ 2.2147603   2.17571788]\n",
      " [-1.68307229  1.49929637]\n",
      " [ 0.46919381 -3.46111533]\n",
      " [ 0.66479552 -0.57761369]\n",
      " [-1.29227826 -1.00709289]\n",
      " [ 1.21147978 -0.4314808 ]]\n",
      "[[0.56615703 0.63672183]\n",
      " [0.18298252 0.444019  ]\n",
      " [0.6932724  0.31481226]\n",
      " [0.29902017 0.69306053]\n",
      " [0.60343976 0.61340131]\n",
      " [0.39440433 0.57336251]\n",
      " [0.50982742 0.27974541]\n",
      " [0.52031727 0.45042588]\n",
      " [0.41536208 0.42500411]\n",
      " [0.5496352  0.45907579]]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND' ] = 'tensorflow'\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    class_labels = [r'A', r'B']\n",
    "    # Set seed for reproducibility\n",
    "    NAME = \"MLP\"\n",
    "    np.random.seed(0)\n",
    "    print(\"Loading data...\")\n",
    "    # Load the data from the CSV files\n",
    "    training_data = pd.read_csv('numerai_training_data.csv', header=0)\n",
    "    print('original train data shape: {},\\t{} \\n\\n \\t:'.format(training_data.shape[0],training_data.shape[1]))\n",
    "\n",
    "    prediction_data = pd.read_csv('numerai_tournament_data.csv', header=0)\n",
    "    print('original prediction data shape: {},\\t{} \\n\\n \\t:'.format(prediction_data.shape[0],prediction_data.shape[1]))\n",
    "    \n",
    "    complete_training_data = pd.concat([training_data, prediction_data])\n",
    "    print('total training / valdation shape {}'.format(complete_training_data))\n",
    "    \n",
    "    # Transform the loaded CSV data into numpy arrays\n",
    "\n",
    "    features = [f for f in list(training_data) if \"feature\" in f]\n",
    "    print(features)\n",
    "\n",
    "    X = training_data[features]\n",
    "#     mini= MinMaxScaler(feature_range=(0,1)) \n",
    "#     X = mini.fit_transform(X)\n",
    "\n",
    "    Y = training_data[\"target_frank\"]\n",
    "    Y= keras.utils.to_categorical(Y,2) \n",
    "\n",
    "    x_prediction = prediction_data[features]\n",
    "#     x_prediction = mini.fit_transform(x_prediction)\n",
    "\n",
    "    ids = prediction_data[\"id\"]  \n",
    "    n = 1  # dimension of each data point\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    sample_train, sample_test, label_train, label_test = train_test_split(X,Y, test_size=.67, random_state=7)\n",
    "    std_scale = StandardScaler()\n",
    "    X = std_scale.fit_transform(sample_train)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    sample_train = pca.fit_transform(X)\n",
    "    sample_test = pca.fit_transform(x_prediction)\n",
    "    \n",
    "\n",
    "    # Scale to the range (-1,+1)\n",
    "    samples = np.append(sample_train, sample_test, axis=0)\n",
    "    minmax_scale = MinMaxScaler((0, 1))\n",
    "    X = minmax_scale.fit_transform(sample_train)\n",
    "    x_prediction = minmax_scale.fit_transform(sample_test)\n",
    "    # Pick training size number of samples from each distro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('finished')\n",
    "\n",
    "#     sample_Total, training_input, test_input, class_labels = train_test_split(X,test_size=.67)\n",
    "\n",
    "#     print(sample_Total.shape[0]) \n",
    "#     print(sample_Total.shape[1])\n",
    "\n",
    "#     temp = [x_prediction[k] for k in x_prediction]\n",
    "#     total_array = np.concatenate(temp)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T06:26:05.530462Z",
     "start_time": "2019-05-03T06:26:05.090131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-825fc421e84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                               test_size=10, n=n, PLOT_DATA=True)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "n = 2  # dimension of each data point\n",
    "\n",
    "sample_Total, training_input, test_input, class_labels = Wine(training_size=40,\n",
    "                                                              test_size=10, n=n, PLOT_DATA=True)\n",
    "\n",
    "print(sample_Total.shape[0]) \n",
    "print(sample_Total.shape[1])\n",
    "\n",
    "temp = [test_input[k] for k in test_input]\n",
    "total_array = np.concatenate(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup an Aqua configuration dictionary to use the quantum `QSVMKernel` algorithm and add a multiclass extension to classify the Wine data set, since it has 3 classes.\n",
    "\n",
    "Although the `AllPairs` extension is used here in the example the following multiclass extensions would also work:\n",
    "\n",
    "    'multiclass_extension': {'name': 'OneAgainstRest'}\n",
    "    'multiclass_extension': {'name': 'ErrorCorrectingCode', 'code_size': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'testing_accuracy' : 0.8695652173913043\n",
      "'test_success_ratio' : 0.8695652173913043\n",
      "'predicted_labels' : [0 0 0 0 0 0 1 0 0 0 1 2 1 1 1 0 1 1 1 1 2 2 2]\n",
      "'predicted_classes' : ['A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'C', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C']\n"
     ]
    }
   ],
   "source": [
    "aqua_dict = {\n",
    "    'problem': {'name': 'svm_classification', 'random_seed': 10598},\n",
    "    'algorithm': {\n",
    "        'name': 'QSVM.Kernel'\n",
    "    },\n",
    "    'feature_map': {'name': 'SecondOrderExpansion', 'depth': 2, 'entangler_map': {0: [1]}},\n",
    "    'multiclass_extension': {'name': 'AllPairs'},\n",
    "    'backend': {'shots': 1024}\n",
    "}\n",
    "\n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "algo_input = SVMInput(training_input, test_input, total_array)\n",
    "result = run_algorithm(aqua_dict, algo_input, backend=backend)\n",
    "for k,v in result.items():\n",
    "    print(\"'{}' : {}\".format(k, v))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
